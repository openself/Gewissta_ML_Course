# Модуль 5.Построение случайного леса с помощью пакета R randomForest
# Лекция 5.1 Построение ансамбля деревьев классификации
# 5.1.1 Подготовка данных
# загружаем данные
data <- read.csv2("C:/Trees/Response.csv")
# выполняем необходимые преобразования
data[, -c(12:13)] <- lapply(data[, -c(12:13)], factor)
set.seed(42)
data$random_number <- runif(nrow(data),0,1)
development <- data[which(data$random_number > 0.3), ]
holdout <- data[ which(data$random_number <= 0.3), ]
development$random_number <- NULL
holdout$random_number <- NULL
# 5.1.2 Построение модели и получение OOB оценки качества
# устанавливаем пакет randomForest
# install.packages("randomForest")
# загружаем пакет randomForest
library(randomForest)
# задаем стартовое значение генератора случайных
# чисел для воспроизводимости результатов
set.seed(152)
# строим случайный лес деревьев классификации
model<-randomForest(response ~., development, importance=TRUE)
# выводим информацию о качестве модели
print(model)
# матрицу ошибок по методу OOB
# можно еще вывести так
table(development$response, predict(model))
# строим график зависимости OOB ошибок классификации
# от количества случайно отбираемых предикторов
plot(model)
# настраиваем оптимальное значение mtry
set.seed(152)
tuneRF(development[,1:13], development[,14], ntreeTry=500, trace=FALSE)
# 5.1.3 Важности предикторов
# выводим важности предикторов
importance(model)
# выводим график важности предикторов
varImpPlot(model)
# 5.1.4 Графики частной зависимости
# строим график частной зависимости для переменной age,
# интересующий класс – класс 1 (класс Есть отклик)
# значение по оси ординат - разность между логарифмом
# доли голосов, поданных деревьями за интересующий класс
# зависимой переменной, и усредненной суммой логарифмов
# голосов, поданных деревьями за каждый класс
partialPlot(model, development, age, 1)
# строим график частной зависимости для переменной cus_leng,
# интересующий класс – класс 1 (класс Есть отклик)
partialPlot(model, development, cus_leng, 1)
# строим график частной зависимости для переменной atm_user,
# интересующий класс – класс 1 (класс Есть отклик)
partialPlot(model, development, atm_user, 1)
# строим график частной зависимости для переменной atm_user,
# интересующий класс – класс 0 (класс Нет отклика)
partialPlot(model, development, atm_user, 0)
# 5.1.5 Вычисление вероятностей классов
# вычисляем вероятности для обучающей и контрольной выборок
prob <- predict(model, development, type="prob")
prob2 <- predict(model, type="prob")
tail(prob, 5)
tail(prob2, 5)
str(prob2)
str(prob)
prob <- predict(model, development, type="prob", predict.all = TRUE)
prob2 <- predict(model, type="prob", predict.all = TRUE)
tail(prob, 5)
tail(prob2, 5)
prob <- predict(model, development, type="prob", predict.all = TRUE)
tail(prob, 5)
prob2 <- predict(model, type="prob", predict.all = TRUE)
tail(prob2, 5)
# выводим вероятности для последних 5 наблюдений
# обучающей выборки, вычисленные по обычному методу
tail(prob, 5)
# выводим вероятности для последних 5 наблюдений
# обучающей выборки, вычисленные по методу OOB
tail(prob_oob, 5)
prob <- predict(model, development, type="prob")
prob_oob <- predict(model, type="prob")
# выводим вероятности для последних 5 наблюдений
# обучающей выборки, вычисленные по обычному методу
tail(prob, 5)
# выводим вероятности для последних 5 наблюдений
# обучающей выборки, вычисленные по методу OOB
tail(prob_oob, 5)
prob <- predict(model, development, type="prob")
prob_oob <- predict(model, type="prob")
# выводим вероятности для последних 5 наблюдений
# обучающей выборки, вычисленные по обычному методу
tail(prob, 5)
# выводим вероятности для последних 5 наблюдений
# обучающей выборки, вычисленные по методу OOB
tail(prob_oob, 5)
# загружаем пакет pROC для построения ROC-кривых
library(pROC)
# строим ROC-кривую для обучающей выборки (на основе
# вероятностей, вычисленных обычным способом)
roc_dev<-plot(roc(development$response, prob_dev[,2], ci=TRUE), percent=TRUE,
print.auc=TRUE, col="#1c61b6")
# вычисляем вероятности классов для контрольной выборки
prob_hold <- predict(model, development, type="prob")
# добавляем ROC-кривую для контрольной выборки
roc_hold<-plot(roc(holdout$response, prob_hold[,2], ci=TRUE), percent=TRUE,
print.auc=TRUE, col="#008600", print.auc.y= .4, add=TRUE)
# создаем легенды к ROC-кривым
legend("bottomright", legend=c("Обучающая выборка (обычный метод)", "
Контрольная выборка"),
col=c("#1c61b6", "#008600"), lwd=2)
prob_dev <- predict(model, development, type="prob")
prob_dev_oob <- predict(model, type="prob")
# выводим вероятности для последних 5 наблюдений
# обучающей выборки, вычисленные по обычному методу
tail(prob_dev, 5)
# выводим вероятности для последних 5 наблюдений
# обучающей выборки, вычисленные по методу OOB
tail(prob_dev_oob, 5)
# 5.1.6 Оценка дискриминирующей способности модели с помощью ROC-кривой
# загружаем пакет pROC для построения ROC-кривых
library(pROC)
# строим ROC-кривую для обучающей выборки (на основе
# вероятностей, вычисленных обычным способом)
roc_dev<-plot(roc(development$response, prob_dev[,2], ci=TRUE), percent=TRUE,
print.auc=TRUE, col="#1c61b6")
# вычисляем вероятности классов для контрольной выборки
prob_hold <- predict(model, development, type="prob")
# добавляем ROC-кривую для контрольной выборки
roc_hold<-plot(roc(holdout$response, prob_hold[,2], ci=TRUE), percent=TRUE,
print.auc=TRUE, col="#008600", print.auc.y= .4, add=TRUE)
# создаем легенды к ROC-кривым
legend("bottomright", legend=c("Обучающая выборка (обычный метод)", "
Контрольная выборка"),
col=c("#1c61b6", "#008600"), lwd=2)
prob_dev <- predict(model, development, type="prob")
prob_dev_oob <- predict(model, type="prob")
# выводим вероятности для последних 5 наблюдений
# обучающей выборки, вычисленные по обычному методу
tail(prob_dev, 5)
# выводим вероятности для последних 5 наблюдений
# обучающей выборки, вычисленные по методу OOB
tail(prob_dev_oob, 5)
# 5.1.6 Оценка дискриминирующей способности модели с помощью ROC-кривой
# загружаем пакет pROC для построения ROC-кривых
library(pROC)
# строим ROC-кривую для обучающей выборки (на основе
# вероятностей, вычисленных обычным способом)
roc_dev<-plot(roc(development$response, prob_dev[,2], ci=TRUE), percent=TRUE,
print.auc=TRUE, col="#1c61b6")
# вычисляем вероятности классов для контрольной выборки
prob_hold <- predict(model, development, type="prob")
# добавляем ROC-кривую для контрольной выборки
roc_hold<-plot(roc(holdout$response, prob_hold[,2], ci=TRUE), percent=TRUE,
print.auc=TRUE, col="#008600", print.auc.y= .4, add=TRUE)
# создаем легенды к ROC-кривым
legend("bottomright", legend=c("Обучающая выборка (обычный метод)", "
Контрольная выборка"),
col=c("#1c61b6", "#008600"), lwd=2)
# загружаем пакет pROC для построения ROC-кривых
library(pROC)
# строим ROC-кривую для обучающей выборки (на основе
# вероятностей, вычисленных обычным способом)
roc_dev<-plot(roc(development$response, prob_dev[,2], ci=TRUE), percent=TRUE,
print.auc=TRUE, col="#1c61b6")
# вычисляем вероятности классов для контрольной выборки
prob_hold <- predict(model, holdout, type="prob")
# добавляем ROC-кривую для контрольной выборки
roc_hold<-plot(roc(holdout$response, prob_hold[,2], ci=TRUE), percent=TRUE,
print.auc=TRUE, col="#008600", print.auc.y= .4, add=TRUE)
# создаем легенды к ROC-кривым
legend("bottomright", legend=c("Обучающая выборка (обычный метод)", "
Контрольная выборка"),
col=c("#1c61b6", "#008600"), lwd=2)
warnings()
# вычисляем вероятности классов для обучающей выборки
# обычным методом и по методу OOB
prob_dev <- predict(model, development, type="prob")
prob_dev_oob <- predict(model, type="prob")
# выводим вероятности для последних 5 наблюдений
# обучающей выборки, вычисленные по обычному методу
tail(prob_dev, 5)
# выводим вероятности для последних 5 наблюдений
# обучающей выборки, вычисленные по методу OOB
tail(prob_dev_oob, 5)
# 5.1.6 Оценка дискриминирующей способности модели с помощью ROC-кривой
# загружаем пакет pROC для построения ROC-кривых
library(pROC)
# строим ROC-кривую для обучающей выборки (на основе
# вероятностей, вычисленных обычным способом)
roc_dev<-plot(roc(development$response, prob_dev[,2], ci=TRUE), percent=TRUE,
print.auc=TRUE, col="#1c61b6")
# вычисляем вероятности классов для контрольной выборки
prob_hold <- predict(model, holdout, type="prob")
# добавляем ROC-кривую для контрольной выборки
roc_hold<-plot(roc(holdout$response, prob_hold[,2], ci=TRUE), percent=TRUE,
print.auc=TRUE, col="#008600", print.auc.y= .4, add=TRUE)
# создаем легенды к ROC-кривым
legend("bottomright", legend=c("Обучающая выборка (обычный метод)", "
Контрольная выборка"),
col=c("#1c61b6", "#008600"), lwd=2)
# вычисляем вероятности классов для обучающей выборки
# обычным методом и по методу OOB
prob_dev <- predict(model, development, type="prob")
prob_dev_oob <- predict(model, type="prob")
# выводим вероятности для последних 5 наблюдений
# обучающей выборки, вычисленные по обычному методу
tail(prob_dev, 5)
# выводим вероятности для последних 5 наблюдений
# обучающей выборки, вычисленные по методу OOB
tail(prob_dev_oob, 5)
# 5.1.6 Оценка дискриминирующей способности модели с помощью ROC-кривой
# загружаем пакет pROC для построения ROC-кривых
library(pROC)
# строим ROC-кривую для обучающей выборки (на основе
# вероятностей, вычисленных обычным способом)
roc_dev<-plot(roc(development$response, prob_dev[,2], ci=TRUE), percent=TRUE,
print.auc=TRUE, col="#1c61b6")
# вычисляем вероятности классов для контрольной выборки
prob_hold <- predict(model, holdout, type="prob")
# добавляем ROC-кривую для контрольной выборки
roc_hold<-plot(roc(holdout$response, prob_hold[,2], ci=TRUE), percent=TRUE,
print.auc=TRUE, col="#008600", print.auc.y= .4, add=TRUE)
# создаем легенды к ROC-кривым
legend("bottomright", legend=c("Обучающая выборка (обычный метод)", "
Контрольная выборка"),
col=c("#1c61b6", "#008600"), lwd=2)
# загружаем пакет pROC для построения ROC-кривых
library(pROC)
# строим ROC-кривую для обучающей выборки (на основе
# вероятностей, вычисленных обычным способом)
roc_dev<-plot(roc(development$response, prob_dev[,2], ci=TRUE), percent=TRUE,
print.auc=TRUE, col="#1c61b6")
# вычисляем вероятности классов для контрольной выборки
prob_hold <- predict(model, holdout, type="prob")
# добавляем ROC-кривую для контрольной выборки
roc_hold<-plot(roc(holdout$response, prob_hold[,2], ci=TRUE), percent=TRUE,
print.auc=TRUE, col="#008600", print.auc.y= .4, add=TRUE)
# создаем легенды к ROC-кривым
legend("bottomright", legend=c("Обучающая выборка (обычный метод)",
"Контрольная выборка"),
col=c("#1c61b6", "#008600"), lwd=2)
# Модуль 5.Построение случайного леса с помощью пакета R randomForest
# Лекция 5.1 Построение ансамбля деревьев классификации
# 5.1.1 Подготовка данных
# загружаем данные
data <- read.csv2("C:/Trees/Response.csv")
# выполняем необходимые преобразования
data[, -c(12:13)] <- lapply(data[, -c(12:13)], factor)
set.seed(42)
data$random_number <- runif(nrow(data),0,1)
development <- data[which(data$random_number > 0.3), ]
holdout <- data[ which(data$random_number <= 0.3), ]
development$random_number <- NULL
holdout$random_number <- NULL
# 5.1.2 Построение модели и получение OOB оценки качества
# устанавливаем пакет randomForest
# install.packages("randomForest")
# загружаем пакет randomForest
library(randomForest)
# задаем стартовое значение генератора случайных
# чисел для воспроизводимости результатов
set.seed(152)
# строим случайный лес деревьев классификации
model<-randomForest(response ~., development, importance=TRUE)
# выводим информацию о качестве модели
print(model)
# матрицу ошибок по методу OOB
# можно еще вывести так
table(development$response, predict(model))
# строим график зависимости OOB ошибок классификации
# от количества случайно отбираемых предикторов
plot(model)
# настраиваем оптимальное значение mtry
set.seed(152)
tuneRF(development[,1:13], development[,14], ntreeTry=500, trace=FALSE)
# 5.1.3 Важности предикторов
# выводим важности предикторов
importance(model)
# выводим график важности предикторов
varImpPlot(model)
# 5.1.4 Графики частной зависимости
# строим график частной зависимости для переменной age,
# интересующий класс – класс 1 (класс Есть отклик)
# значение по оси ординат - разность между логарифмом
# доли голосов, поданных деревьями за интересующий класс
# зависимой переменной, и усредненной суммой логарифмов
# голосов, поданных деревьями за каждый класс
partialPlot(model, development, age, 1)
# строим график частной зависимости для переменной cus_leng,
# интересующий класс – класс 1 (класс Есть отклик)
partialPlot(model, development, cus_leng, 1)
# строим график частной зависимости для переменной atm_user,
# интересующий класс – класс 1 (класс Есть отклик)
partialPlot(model, development, atm_user, 1)
# строим график частной зависимости для переменной atm_user,
# интересующий класс – класс 0 (класс Нет отклика)
partialPlot(model, development, atm_user, 0)
# 5.1.5 Вычисление вероятностей классов
# вычисляем вероятности классов для обучающей выборки
# обычным методом и по методу OOB
prob_dev <- predict(model, development, type="prob")
prob_dev_oob <- predict(model, type="prob")
# выводим вероятности для последних 5 наблюдений
# обучающей выборки, вычисленные по обычному методу
tail(prob_dev, 5)
# выводим вероятности для последних 5 наблюдений
# обучающей выборки, вычисленные по методу OOB
tail(prob_dev_oob, 5)
# 5.1.6 Оценка дискриминирующей способности модели с помощью ROC-кривой
# загружаем пакет pROC для построения ROC-кривых
library(pROC)
# строим ROC-кривую для обучающей выборки (на основе
# вероятностей, вычисленных обычным способом)
roc_dev<-plot(roc(development$response, prob_dev[,2], ci=TRUE), percent=TRUE,
print.auc=TRUE, col="#1c61b6")
# вычисляем вероятности классов для контрольной выборки
prob_hold <- predict(model, holdout, type="prob")
# добавляем ROC-кривую для контрольной выборки
roc_hold<-plot(roc(holdout$response, prob_hold[,2], ci=TRUE), percent=TRUE,
print.auc=TRUE, col="#008600", print.auc.y= .4, add=TRUE)
# создаем легенды к ROC-кривым
legend("bottomright", legend=c("Обучающая выборка (обычный метод)",
"Контрольная выборка"),
col=c("#1c61b6", "#008600"), lwd=2)
# строим ROC-кривую для обучающей выборки (на основе
# вероятностей, вычисленных по способу OOB)
roc_dev<-plot(roc(development$response, prob_dev_oob[,2], ci=TRUE), percent=TRUE,
print.auc=TRUE, col="#1c61b6")
# добавляем ROC-кривую для контрольной выборки
roc_hold<-plot(roc(holdout$response, prob_hold[,2], ci=TRUE), percent=TRUE,
print.auc=TRUE, col="#008600", print.auc.y= .4, add=TRUE)
# cоздаем легенды к ROC-кривым
legend("bottomright", legend=c("Обучающая выборка (метод OOB)",
"Контрольная выборка"),
col=c("#1c61b6", "#008600"), lwd=2)
# загружаем пакет rpart
library(rpart)
# подгоняем модель CART
set.seed(42)
model_cart <-rpart(response ~., development)
# записываем вероятности, спрогнозированные деревом CART
# для контрольной выборки, в объект prob_hold_cart
prob_hold_cart <- predict(model_cart, holdout, type="prob")
# визуализируем обе ROC-кривые
rf<-plot(roc(holdout$response, prob_hold[,2], ci=TRUE),
percent=TRUE, print.auc=TRUE, col="#1c61b6")
cart<-plot(roc(holdout$response, prob_hold_cart[,2], ci=TRUE), percent=TRUE,
print.auc=TRUE, col="#008600", print.auc.y= .4, add=TRUE)
# создаем легенды к ROC-кривым
legend("bottomright", legend=c("Случайный лес", "Дерево CRT"),
col=c("#1c61b6", "#008600"), lwd=2)
# задаем стартовое значение генератора
# случайных чисел
set.seed(152)
# вычисляем классы зависимой переменной
# для обучающей выборки обычным способом
resp_dev <- predict(model, development, type="response")
# выводим классы зависимой переменной
# для последних 5 наблюдений обучающей
# выборки, вычисленные по обычному методу
tail(resp_dev, 5)
# выводим матрицу ошибок для обучающей выборки
# на основе классов, вычисленных обычным методом
table(development$response, resp_dev)
# задаем стартовое значение генератора
# случайных чисел
set.seed(152)
# вычисляем классы зависимой переменной
# для контрольной выборки
resp_hold <- predict(model, holdout, type="response")
# выводим матрицу ошибок для контрольной выборки
table(holdout$response, resp_hold)
getTree(model, k=1, labelVar=FALSE)
getTree(model, k=1, labelVar=TRUE)
getTree(model, k=1, labelVar=T)
getTree(model, k=1, labelVar=F)[1:100]
head(getTree(model, k=1, labelVar=F), 10)
head(info_tree1, 10)
info_tree1 <- getTree(model, k=1, labelVar=F)
head(info_tree1, 10)
info_tree1 <- getTree(model, k=1, labelVar=F)
head(info_tree1, 15)
